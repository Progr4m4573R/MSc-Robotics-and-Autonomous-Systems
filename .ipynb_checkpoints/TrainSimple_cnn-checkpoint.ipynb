{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bd6e90d-c659-4bea-bbd6-1ceca95daf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "\n",
    "source: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf877f3e-3be3-4b31-98c8-e73b6b3b7a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88147e65-2450-485d-989e-dd0bef920762",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['pneumonia', 'no_pneumonia']\n",
    "img_size = 150\n",
    "def get_training_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir,label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "                data.append([resized_arr, class_num])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a40139d-15c5-4a73-bf7c-92d36520a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computing\\AppData\\Local\\Temp\\ipykernel_11272\\3388793708.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(data)\n"
     ]
    }
   ],
   "source": [
    "datadir = os.getcwd()\n",
    "train = get_training_data('C:/Users/Computing/Downloads/data-task1/train/')\n",
    "test = get_training_data('C:/Users/Computing/Downloads/data-task1/test/')\n",
    "val = get_training_data('C:/Users/Computing/Downloads/data-task1/val/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fd44186-50dd-4610-b64a-a644c46df79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = []\n",
    "test_labels = []\n",
    "for i in train:\n",
    "    if(i[1] == 0):\n",
    "        label = 0\n",
    "        l.append(\"Pneumonia\")\n",
    "    else:\n",
    "        label = 1\n",
    "        l.append(\"Normal\")\n",
    "    test_labels.append(label)\n",
    "test_labels = np.array(test_labels)\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(l)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e10a4a9-a986-439a-8dc7-77e090e7b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "for feature, label in test:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)\n",
    "    \n",
    "for feature, label in val:\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36e1e8ac-fcd6-4ca6-b0fe-00d1675ef0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3000, 150, 150, 1)\n",
      "3000 train samples\n",
      "500 test samples\n",
      "Epoch 1/12\n",
      "24/24 [==============================] - 49s 2s/step - loss: 1.5775 - accuracy: 0.7803 - val_loss: 0.9908 - val_accuracy: 0.7900\n",
      "Epoch 2/12\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.8519 - accuracy: 0.7860 - val_loss: 0.7158 - val_accuracy: 0.7900\n",
      "Epoch 3/12\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.6921 - accuracy: 0.7860 - val_loss: 0.6295 - val_accuracy: 0.7900\n",
      "Epoch 4/12\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.6269 - accuracy: 0.7860 - val_loss: 0.5870 - val_accuracy: 0.7900\n",
      "Epoch 5/12\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.5937 - accuracy: 0.7860 - val_loss: 0.5609 - val_accuracy: 0.7900\n",
      "Epoch 6/12\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.5728 - accuracy: 0.7860 - val_loss: 0.5435 - val_accuracy: 0.7900\n",
      "Epoch 7/12\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.5538 - accuracy: 0.7860 - val_loss: 0.5304 - val_accuracy: 0.7900\n",
      "Epoch 8/12\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.5418 - accuracy: 0.7860 - val_loss: 0.5214 - val_accuracy: 0.7900\n",
      "Epoch 9/12\n",
      "24/24 [==============================] - 49s 2s/step - loss: 0.5293 - accuracy: 0.7857 - val_loss: 0.5128 - val_accuracy: 0.7900\n",
      "Epoch 10/12\n",
      "24/24 [==============================] - 50s 2s/step - loss: 0.5241 - accuracy: 0.7857 - val_loss: 0.5063 - val_accuracy: 0.7900\n",
      "Epoch 11/12\n",
      "24/24 [==============================] - 50s 2s/step - loss: 0.5200 - accuracy: 0.7850 - val_loss: 0.5010 - val_accuracy: 0.7900\n",
      "Epoch 12/12\n",
      "24/24 [==============================] - 50s 2s/step - loss: 0.5134 - accuracy: 0.7860 - val_loss: 0.4964 - val_accuracy: 0.7900\n",
      "Test loss: 0.49637818336486816\n",
      "Test accuracy: 0.7900000214576721\n",
      "--- 592.9131944179535 seconds ---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "for feature, label in test:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)\n",
    "    \n",
    "for feature, label in val:\n",
    "    x_val.append(feature)\n",
    "    y_val.append(label)\n",
    "\n",
    "x_train = np.array(x_train) / 255\n",
    "x_test = np.array(x_test) / 255\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
    "input_shape = (150,150,1)\n",
    "#CREATE siole model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e00f7d-dfba-4854-8cf7-e8d06a05141b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
