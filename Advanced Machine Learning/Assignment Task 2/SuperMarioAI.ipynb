{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe584c6-410e-4419-844e-d9b97524bff8",
   "metadata": {},
   "source": [
    "The Reinforcement Learning Algorithm implemented in this Assignment is PPO, Proximal Policy Optimization with CNN, Convolutional Neural Network Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65afba86-c545-4161-a4ab-7cb49294b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gym_super_mario_bros==7.3.0 nes_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473c0186-3843-4050-a65f-b146b8d80404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the game\n",
    "import gym_super_mario_bros\n",
    "#import the joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "#Import thje SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f48cac99-1cf4-46d7-a914-ef267041aeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NOOP'],\n",
       " ['right'],\n",
       " ['right', 'A'],\n",
       " ['right', 'B'],\n",
       " ['right', 'A', 'B'],\n",
       " ['A'],\n",
       " ['left']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sIMPLE ACTIONS is a libraary that simplifies the actions that the ai can take to make it less complicated\n",
    "SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61c59cf8-eba9-408b-b38d-c4b11b7be991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')# setup which emulatiuon version to use https://github.com/Kautenja/gym-super-mario-bros\n",
    "#env.action_space\n",
    "env = JoypadSpace(env,SIMPLE_MOVEMENT)#SIMPLIFY THE NUMBER OF ACTIONS the ai can take from 256 to 7\n",
    "#env.action_space#tells the number of actions available\n",
    "\n",
    "#observation space shows what output the game returns,  i.e the number of pixles in a frame of the game\n",
    "env.observation_space.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c571e63b-4864-4de1-9466-d002d65c1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create a flag for restarting the game\n",
    "# done = True\n",
    "# for frame in range(100000): # for every frame of the game\n",
    "#     if done:#if the game isnt started we start if via  start =  True\n",
    "#         env.reset()#resets game environment to start\n",
    "#     state, reward, done, info = env.step(env.action_space.sample())#parses a random action to the game\n",
    "#     env.render()#this shows the game on the screen\n",
    "# env.close()# this runs the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d65e80ea-2960-4652-9cd9-ce769d43c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints random actions from the simple movement function\n",
    "#SIMPLE_MOVEMENT[env.action_space.sample()]\n",
    "#prints a random number from the action_ space\n",
    "#env.action_space.sample()\n",
    "#Shows all available movements\n",
    "#SIMPLE_MOVEMENT\n",
    "#state = env.reset()#returns a state showing a particular frame from the game\n",
    "#env.step(1)[1] #shoes the rewards for eah step\n",
    "#based on the youtube tutorial Build an Mario AI Model with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49624d50-8b99-4c5c-96a1-8c2a3c1cf583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nstall pytorch https://pytorch.org/get-started/locally/\n",
    "#!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe749493-3465-406d-a3f4-ba33111e261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install stable baselines AI library https://stable-baselines3.readthedocs.io/en/master/guide/install.html\n",
    "#!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c739f387-d414-490c-9cfb-4ebd0cf71aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the environment for AI training\n",
    "#import frame stacker Wrapper and Grayscaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation # allows us to capture multiple frame while playing the game\n",
    "#Import Vectorization Wrappers\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv #converts the game into grayscale to cut down information\n",
    "#Import Matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "465d1be0-6d81-4626-a3c4-6528d262a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create the base environment\n",
    "#the AI library i will use is the Stable Baselines \n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')# setup which emulatiuon version to use https://github.com/Kautenja/gym-super-mario-bros\n",
    "# 2. simplify the controls\n",
    "env = JoypadSpace(env,SIMPLE_MOVEMENT)#SIMPLIFY THE NUMBER OF ACTIONS the ai can take from 256 to 7\n",
    "# 3. Grayscale\n",
    "env = GrayScaleObservation(env, keep_dim=True)# required to keep the last dimention which determins colour to do frame stacking\n",
    "# 4. Wrap inside dummy environment\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# 5. Stack the frames\n",
    "env = VecFrameStack(env, 4, channels_order='last') #by parsing the env to the frame stack we can specify how many frames to stack, last argument specifies where the rgb channel is, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e52c0023-7d63-423d-9395-c1a6af5b946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99934a25-9480-4fa0-b3bb-4c497cb646e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, info = env.step([env.action_space.sample()])#parses a random action to the game, this has to be in an array because the environment is now vectorised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26358d2a-e5fa-4ac6-b971-0e3ec4d73ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1735baa2d40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAD8CAYAAAC2EFsiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArPElEQVR4nO3deXQc1Z3o8e/tVWrtu40kb7KQd2RbNjY4Dga8QCA2BgeYsAwEHCbOQOBlHpDknGRyTpb3MsAkYQaCJ0wgQ4INdsLOw9gYW+AFGctGi1fJm2RL1r5v3ff90a2WZG0tqaRuyb/POX3UqqV/vy6Vfn3r1q1qpbVGCCGMYPJ3AkKIsUMKihDCMFJQhBCGkYIihDCMFBQhhGGkoAghDDNsBUUptUopdVQpdUIp9dRwxRFCBA41HONQlFJm4BiwHDgHfAHcrbXOMzyYECJgDFcLZSFwQmtdoLVuAV4HVg9TLCFEgLAM0+smAmc7/X4OuLq3hYODI3RExLhhSkUIMRQlJcfKtNZxviw7XAWlX0qp9cB6gLCwBO655w/+SkUI0Ydnnll22tdlh+uQpwhI7vR7kmeal9b6Ja11htY6w+GIGKY0hBAjabgKyhdAqlJqslLKBtwFvD1MsYQQAWJYDnm01m1Kqe8D/w8wAy9rrXOHI5YQInAMWx+K1vp94P3hen0hROCRkbJCCMNIQRFCGEYKihDCMFJQhBCGkYIihDCMFBQhhGGkoAghDCMFRQhhGL9dHDjcGhtN5OWFEx/fSHJyMwBHjoRQX29l7txqTCZNS4viq6/c1xGNG9dAYmILAHl5oTQ2dt004eEtpKY2AHDqVBDl5UFd5lutTubMqaW62syJE2Fd5s2ZU43VKt9/1J/iYhvnzztIS6shNNQFwJdfRmCxuPrdtgcORHZ7vQkT6oiLawPg0KFwnE7FvHnVPcbsbP78KkPez6FD4bS1df3Mjo1tZOLE5l73odTU+j7324MHe77uLTW1lvBwpyF5D8WYbaHU15vYvXs2n346lbNn7eTkhLJr1zR2756NywVOp2Lnzis4fHgilZXBfPppCsXFNgAOHpzA7t2zMZtdWK1OWltN7NqVxpEjIQCYzRqr1cmBAylkZs7CYnFhsWjq6kzs3DmBwsJYrFYnVquTQ4cm8cknV+ByKX9ujlHh9Okwdu+eTXV1RzHPzJzF/v1T+9y2TqciM3MWWVlTvfOKiyP49NNJVFS4X2vfvlQyM2f1GrO+3obV6mTv3ml8+mm8Ie/HanVhsbjIzJzFl19OwWp1YvL8x/W2D/W13zqddHuf7Q+lAuMDa8y2UNqVlUWzc+dUmprsNDS4P4m0hvfem0RJSTS33nqY8HAnn31mYseOVFasOOZdd86cWkwmTWWlmb17Qzl7NoJp0+pJTm4mObmZgwdbaGwMZs6cWpTSlJVZKCxMIj39GHPm1AKQl9dIXt4Urr++2Lszif7t2DGOpUtLvL83NZl63bbLlhUDYLW2eee1tJjJzJxNbe1ZoqPb+o2XklJFYmILEREHefvt+TQ3W1mxoqjf9foyY0YdWit27gS7vcWbG9DnPgQ977ftOr/PQDPmCwpAeXl0t2mnTiUSFlbH+PGtAERH15OXN4XGxq7/9S0tinfemT4ieQq3bdumUVcXQnFxDFoPvGV35oyd7OzJg4o9cWIzWivOnInnkjtujLie9luA+noHf/lLxz65YMFp7+G4v435gjJr1glMJk1CQh2HDiVTWhrrnVdXF8LGjfMAaG21dlv3j3+ci9YKm62V9es/w2IJjGblWFdV5e4nKCvr+R+qN+1/T6fTzLRpZ1i48CJ2++j8m/W13zocjaxZc9T7u80WOO9xzDfCLRYXy5aVMGNGPSaTq8u80NB6HnzwIA8+eJCMjGPd1r333mwaG4Oprg5n27aJXf5wnT85O9/nu/1YVmvlXSZQjm9HC6U09967h6Cgpi7brr9tGxpaz0035dDcbOfw4amcPBmC2dx127eve2nLR2v3vI0b52E2O3nggexhenddc+kcv7O+9lulNMHBHQ+zedhT9dmYbaEoBXZ7MxZLR4eV1erEbnf3nNtsLdhsrd4dzmp1Ybc3YzK5j1Ht9mZsNs0jj3zGyy8voLg4jk8+aWDZshJ27BjH0aMTvK/zhz8swOFo5P77v2L16iw++GAO+fkTvbl85zufS+vGBxaL+2+wenU2MTFtPPLIF7z44gKs1jZiY9t63bZWq/b+PZOSWrjllgN89NFsMjOnExl5iOTkZmy2VpxOMy++uMC77rRppwkNbcFub+add9K907/3vX2GfgjYbC1YrV37cXrbh265Jb/f/ba52dblfQDccssh71khfxqWr9EYqHHj0vRw3VO2pUXR1ORuiIWEuLp8YmmtqK11z7PbXd2axzU17tJvMmnvacx29fUmnE73J8ylp+uGEnOwXC6FywUREZrmZmjrvx/Sa7Dv01+amky0tKhu29YXNTXmHt+nv9TVmbxnADtvX3/sQ7155pllB7TWGb4sO2ZbKADNzYqcnAgKCuKoqIjg2muPeJqQGq0Vp07ZycpKprHRTkJCJV/72nkcDveOVlJiZffuiTidZurrg1m9OoeYGPd/aVWVmX37xlFT4+D8+XjuuOMLrriiZcgxB8vlUlRUmKmstHHPPU6amlzk5rb6VFQG+z79pb7exK5diRw9Oom7795LQkKrz+sWF9t4442FREVVcd99OcOYpW/Kyy38/e+zqa0NxWJp4/vf3wP4Zx8yypjtQ2luVnzxRQy1tXbWrTvOwoXH+eyzaeTkhKK1Ij8/hE8+mca6dcdZseIoZWURfP55Ag0NJk6ftrN161zWrj3J2rXHiImp5oMP0igpsVJebuHjjycza9ZF1q07zowZBWzZkkFBQdCQYg5FY6OistI9huZ//sfMokWJhIa652mtKCzsGEBVUWGhutrdIhns+/SnsjIrFy8O7qbmhw8bM77ECBcuWHn//TRiY6swmztaJv7ah4wSGFkMg9paM1lZHafW5s6tJiKilh070mlrg23b0r3zxo1rJS2tmJycqVy8aCUzM4XmZjsAVqtm6dIzlJVFc/hwHMeORXDu3HjvujfeeB6tFTt2TB9SzOHicsH58yEcORJCZaWZ48fDvafGB/s+/WnixGYmTy7pNt3lUmRlRXZ7tB/OAaxc6d/TwO2Ki23s2DGVuLhqVq48jcXS0ZQMxH1oIMb0IY9wj8hcsKCCr74KJy8viqlTqwd0mDBauEeRzu42PS5uf8D0/bQ7fTqM0tJYQkMb+fzzeNraLGityMyMZdq0Kn+nNyRjtoUSEeFk0aJcCgrGc/JksHf6qlVfYrHALbccoKEhmN27O74QLT39GPHxrSxbdsLT8z/JOy8+vox580qZPr2KCROKycycTH29e/OZTC5WrcodUszh1NamKC8PISSkhfJyu3f6YN9nILJY4Lbb9nd7DPe2HYzp06u47bb9XHXVeVJSKjGZXCilmTSpJmD3IV+N6bM8LS3u49H8/GSCg5tZtKiQyZObvJ1bZ87YePfduURG1jB5cgnz5lUSFOTu3KqosPDaawuJjq4iJKSR668/4/2kq6sz8c47V9LaasFsdrFy5TFiY9uGHHOwJk9WhIdbePNNK9/5jqax0Ul2dgutre5i8tZbKdx4YyHBwS4OHYokMrLZO7JysO/TH4qKbOzcOZW6OgeNjcFERlZjtbZx1135/Z7tefNN9zD2srJoLJY2oqKqmTKlhMWLy0co+9698MJCnE6zt1PWH/tQXwZylmdMFxRw/0O1trpPy9ntGpOp6+m3pib3PItFd7siuL2vQSm6/cGam5X3dF9wcNd5Q4k5GBYLLF4czHXXTWPHjnyysppoaekYLNXUZPLm39bWEXuo73OkOZ2KlpbuQ/F9yevSSyrAfTgYCKNM23Pr/D5Geh/qi5w27sRi0b0OKmsfcdibvnZU97n/ntcdSszBaGuDzz5rZM+eg7hc7aM+O+Z3LhI95TXY9znSzObBbzt/F8O+9JTbSO9DRhnzBeVy4XK5H0L405jtlBVCjDwpKEIIw0hBEUIYRgqKEMIwUlCEEIaRgiKEMIwUFCGEYaSgCCEMIwVFCGEYKShCCMNIQRFCGGZI1/IopU4BtYATaNNaZyilooFNwCTgFPAtrXXl0NIUQowGRrRQlmmt0ztd3vwUsF1rnQps9/wuxKCYTJCRYfM+JkyQ74gOZMNxyLMaeMXz/BVgzTDEEJcBpWDZshBOnmzxPoKDTUycKEUlUA319gUa+Ei5v5HoD1rrl4AErfV5z/wLQMIQY4jL0M03RxAaauOllyr405++5p0+Y0YBjz12gaQkF+fOBeY9QS5nQy0oS7TWRUqpeGCbUupI55laa616+Qo2pdR6YD1AWJjUHNHhm9+MYuPGOkpLXezYsbjLvLy8KdTWFhMdbWbhwgg++qicujo/JSq6GdIhj9a6yPOzFPgbsBAoUUqNB/D8LO1l3Ze01hla6wyHY3DfsyLGpqSkKLKyxrN9e3q37yAG+M1v0ggJsfDss/WsW5eEzeaHJEWPBl1QlFIhSqmw9ufACiAHeBu437PY/cBbQ01SCIDExAvMn3+EkpI4Hn54Gu+9l86yZZE8/vgslHSrBIShHPIkAH9T7r+kBfiL1vpDpdQXwGal1HeA08C3hp6muByYTHD77bGsX1/GiRNzMJlc3H33PpqazGzZspDi4gTCwhqZPr2A/PwpAFRUROFwNPk5c9Fu0AVFa10AXNXD9HLghqEkJS4fJhMEe75+ZvHiUH73u2p27lwEwNq1X/DXv17tPezRWnHkyGQu7ZarqKjG4YD6ejCb3d8C0Nw8om9DeMhNqoXfmEwwaZKJG29MBuD3vz/Dpk1LvPO3bFnY43qX9qukpMRRUxPNT3+6l9RUMykpoXz6abV01vqBFBThF0rBlVeasdkUM2ZM8Eyd0Oc6fcnMzCMtzUxDg4uNGxt5+OEI3nuv2phkhc/kWh7hN83NLh58cHH/C/bD5TKxZk0alZVOfvCDjhbOpEmKyMghv7wYAGmhiBG3bFkIZrPi1lvTDXvNpqYgnnzSPQAuNzeWgoISrFZFWpqNvLxmamsNCyX6IAVFjKibbgpn69Y67xewD4fc3BR+/3tNa6uFZ5+tJCyshdpaGVU7EqSgiBE1Y0Yi994LpaWxwxonJ2eq55lc6D6SpA9FjKj//u98PvqoBputZdhj/fSnu7lwoYnSUmmdjBQpKGJEVVTA5s1FFBTUopQmPLyWZcsOeceW9HLpF9AxUtYXjz6ayfTpdvLy2mhrMyR14QMpKGLENTTAb3+bx9mzFTQ12Tl6dByLF+diNju59tocxo8v7VJgzGYnsbEVTJt2gezs1C6vZTK5eixCzz9/DaWlraSmmmVY/giSgiL8orUVXnghj+zsCxQXJ3DhQgTr1n1BUlI9y5efJDa2gqCgJhyOBu65Zx8333yUhIQmrr46n6CgJu/j1lsPYDY7u72+y2Xi0UevJS7ORoJczD5ipFNW+I3LBTU1jcyceRKA7dtTuXgxhiVLvuLaawuIiGgFoLraSnW1jSNHxvO1rxWSmvolAHV1Ft5/fzZtbd1349jYChISKvn731uJiRm593S5k4Ii/KaxET78sJQ33pgIwPvv5/Pss6lkZs4GYNmyQ5hMmszM6cybd4Lz5+PZu7eNtLQSAPbvT6GxMRilNMuWHWLHjnQiI6tZuLCAG26o49ZbJ/LBB07OnvXbW7zsKK393wM+blyavueeP/g7DeFns2ZZKCtr4/hxE2++OZvq6nDMZiff+94eVqxw8Pe/N5KXF8mePTO969x1115CQ53cc08kf/5zFQkJLm65JY4jRyo5fFh6Y43wzDPLDnS6Z3SfpIUiAkZOThszZ5qZPTuYK688RHOz+5qfmTOD2b+/nrVrQ1mypJabbtrtXWf2bAdWq513361g7dpQqqpa2Lz5oh/fxeVNCooIKLm5TnJz65g1y4LdbsLl0uza1QjAtm11xMfD5Mkdt2jbs6eBFs+Qlm3b5PJif5OCIgJSTk7PhyulpVBaOvyD4sTgyGljIYRhpKAIIQwjBUUIYRgpKEIIw0hBEUIYRgqKEMIwUlCEEIaRgiKEMIwUFCGEYaSgCCEMIwVFCGEYKShCCMNIQRFCGEYKihDCMFJQhBCGkYIihDCMFBQhhGGkoAghDCMFRQhhGCkoQgjDSEERQhim34KilHpZKVWqlMrpNC1aKbVNKXXc8zPKM10ppX6nlDqhlDqslJo3nMkLIQKLLy2UPwGrLpn2FLBda50KbPf8DnATkOp5rAdeMCZNIcRo0G9B0VrvAioumbwaeMXz/BVgTafpr2q3vUCkUmq8QbkKIQLcYPtQErTW5z3PLwAJnueJQOevpj7nmdaNUmq9UipLKZXV0FA9yDSEEIFkyJ2y2v1t6wP+xnWt9Uta6wytdYbDETHUNIQQAWCwBaWk/VDG87PUM70ISO60XJJnmhDiMjDYgvI2cL/n+f3AW52m3+c527MIqO50aCSEGOP6/bJ0pdRfgeuAWKXUOeCnwK+BzUqp7wCngW95Fn8fuBk4ATQADwxDzkKIANVvQdFa393LrBt6WFYDG4aalBBidJKRskIIw0hBEUIYRgqKEMIwUlCEEIaRgiKEMIwUFCGEYaSgCCEMIwVFCGEYKShCCMNIQRFCGEYKihDCMFJQhBCGkYIihDCMFBQhhGGkoAghDCMFRQhhGCkoQgjDSEERQhhGCooQwjBSUIQQhpGCIoQwjBQUIYRhpKAIIQwjBUUIYRgpKEIIw0hBEUIYRgqKEMIwUlCEEIaRgiKEMIwUFCGEYaSgCCEMIwVFCGEYKShCCMNIQRFCGEYKihDCMFJQhBCG6begKKVeVkqVKqVyOk37mVKqSCmV7Xnc3Gne00qpE0qpo0qplcOVuBAi8PjSQvkTsKqH6c9prdM9j/cBlFIzgLuAmZ51/lMpZTYqWSFEYOu3oGitdwEVPr7eauB1rXWz1roQOAEsHEJ+QohRZCh9KN9XSh32HBJFeaYlAmc7LXPOM00IcRkYbEF5AUgB0oHzwDMDfQGl1HqlVJZSKquhoXqQaQghAsmgCorWukRr7dRau4CNdBzWFAHJnRZN8kzr6TVe0lpnaK0zHI6IwaQhhAgwgyooSqnxnX69DWg/A/Q2cJdSyq6UmgykAvuHlqIQYrSw9LeAUuqvwHVArFLqHPBT4DqlVDqggVPAdwG01rlKqc1AHtAGbNBaO4clcyFEwOm3oGit7+5h8h/7WP4XwC+GkpQQYnSSkbJCCMNIQRFCGEYKihDCMFJQhBCGkYIihDCMFBQhhGGkoAghDCMFRQhhGCkoQgjDSEERQhhGCooQwjBSUIQQhpGCIoQwjBQUIYRhpKAIIQzT7/1QLhdf+1owy5fP7jLN5XLxr/+ahdZ+SkqIUeayLChKgckEUVHwwx8uASA39ySbNh3ospzJpPjVr9zzT548w8svn0FrcLlGPGUhRoXLsqA4HPCjHy2mvr6BV1/d451+aUvE5dK8+uoelIKkJAc///lidu3KYfv2WtraRjhpIUaBy66gxMbCQw/N5rXX9vt0KKMUJCY6uOqqCWzdeoDJk8NZtKiN/fsbaWkZ/nyFGE0uq07Z5GTFt741hffey/e5X8RmM7FixXzi4+PIyLiC3NxKkpLCmDfPjs02vPkKMdpcNgUlNdXEddeN4/PPz9LWNrRe1kOHypk0KYKrrw7Gctm18YTo3WVRUNLSzFx1VTT5+eU0N/vWozpnTgxz58b2Ov/QoXISEkK48cZwlDIqUyFGtzFfUK680sSsWZGcPl1Dfb3vXxE0e/YU5s6dRmurJisrj6qqao4eLe2yTG5uJRaLiXXr4oxOW4hRaUwXlEmTFPPnx3HmTC11dYP7vjGXS5ObW8HOnUcoKWnuNr+goJby8gbuv/+KoaYrxKg3ZgtKQgLceGMyR49WDLqYtGtr05SX93xKR2s4f76JU6eqeOCBpCHFEWK0G5NdimFhcM8909m27TitrYPrgH3zTfcgN1/OBmkNFy82o1QF3/72OP7ylwsyulZclsZUC0UpCAqCJ56Yz4cfHht0MQFobnb53IEL7qJSWtpMWVk9q1dHYxpTW1YI34yp3d7hgKeeymDz5my/DI/XGs6caQDguutC5JSyuOyMmYISGwsbNszkjTcO+jsVjh6tJi4uhIwMO1arv7MRYuSMiYIyYYJi7dqJfPjh0YC5cO/w4XKmTIlk3jwpKuLyMeoLSkqKiSVL4snKKh5Sn8lwOHiwjClTIlm0KBiz2d/ZCDH8RnVBSU01kZ4exfHjlTQ2BkjT5BLZ2WUkJISwYoWMqBVj36jtNpwyxcScOVGcO1fn8ziT+fPjyc0to6nJuOKjFCxZksTu3ed6XSY3t5KUlDDuuCOWN94oMyy2CDwLFthITY3y/r5pUwlOH3ZPsxnuvDPB+/uxY5VkZfl2OftgYw6HUVlQkpIUixfHc+yY74PW5s+PZ+bMKSQmxvD++0cGfIFgS0vX5a1WhVKwYsVUEhPHYbdb+fjjwl7XLyio5Yorgrn33vH8+c/nBxRbjA7z5lmprGzjpZcueqc9/vgE/uu/zvQ5LkkpePDBCTz3XMeH0rx5kJ5uJTu7dVhiDpdRd8gTEwPf+MZE8vPLBzQCNjIyBKvVSlxc7IAPPZqbNS5X10dLi/uxc2cBAPHxMX2+htZQXNzI2bPV3Hvv+IElIAJaUpLi6afn4HLBpk3hHDgQ6338+MelPPZYWq/rfve7k3jyydn8+MelXdZ7/fUwLBZFWlrPnW9DiTmcRlVBcTjgoYdmsWfPOZ/6TJTqeAyW1lBV5aK6WlNQAJ98YqegAPbvN9Haqlmz5iqUjwHaB78VF9dw553x0qcyBkRFwde/nsC6dad58cUw6uq63iSnqCiU6OgI4uLggQeSuvzNH3poAj//eRHf+tYZzpwJ77Jeba0dl0tjtyseeWQyERHGxBxu/RYUpVSyUuoTpVSeUipXKfWYZ3q0UmqbUuq452eUZ7pSSv1OKXVCKXVYKTXPiERtNnjyyQW8+26+z2dzkpMdPPDAEmbOjEJ72n+uAZ5XLipycviwjepqKCgIorXVhNMJTqfik0+CuO++HFpaWnD6eNDafu1PbW0zN90UISNqRzmlwGw2UVtrp7m5aw+C2ezC6TSxZk0+t98+mf/8z2Juvz3W+ze32Sw0NJiprbV3OTxx3/NY89vfRjJ+fDC/+MVZHnggDYej4wNysDGHmy9h2oD/pbWeASwCNiilZgBPAdu11qnAds/vADcBqZ7HeuCFoSYZEgJPPz2fTZu+HNA4E6WU97FjxymKis6zefPeAZ9eNps1wcGQnNwEwJkzdpKSWnE42jCZ4L77sti0yfcBdVpDYWEdDoeVJUvkJk2jlftSD0VtrXu/sFqdBAe3Yja7d9I77igjJKSFyspg7r67nv37Y/noozJuuCGUoCBoaGjG5XL3xQUHtxIc7O4vSUqqYfHiMkwmzY9+FExOTjS33VbJ009fPaSYI6HfgqK1Pq+1/tLzvBbIBxKB1cArnsVeAdZ4nq8GXtVue4FIpdSgOw3i4uCRR6azZcuhIXcyffjhiQHdEwXc1walprZy8KCD06eDARg/vgWTCSZNaiUjo4nlywfXpe6+nWQ4c+faZPDbKOO+cbnimmti+MEPLNjtbcyeXcmtt1YSH+++/GLTpnhWrqzqdsgRFmbnhhsi+M1vSjh3LoyoqEZuuaWS5csrATh7NpzSUispKdXd4g425kgZ0GejUmoSMBfYByRordtPV1wA2s95JQJnO612zjNtwKc2kpMVK1cms337CZzOgVeTxsY2iorOU1vb/T4mvoqNNVNd7SIqqgWl3Ic6tbVmmpvdnywTJw6tyh08WEZGRjxQzsGDLXI3/QA3aZIiKMj9OTx1ahj//M/u5zExTTQ0mNm8uetd/rZsie/y+8WLCpNJ8eabteTluZddsKCWN9+M7/KBefx4ZLfY+/cfZc6ciEHFbGpyEhEB1dXuIRenT7uG5dSy0j5+7CulQoFPgV9orbcqpaq01pGd5ldqraOUUu8Cv9ZaZ3qmbwee1FpnXfJ663EfEhEWljB//frXu8SbMsXEwoWxnDhRNeBWhZHq613U1GisVrDZFPX17udBQcp7XOpwDP0Ade7cWM6ereGzzxoD5vIB0VVampmYGCtKuQ9bf/3r8FFzm4pHHiknJMRMY6OTyEgrLhfs3dvkU/7PPLPsgNY6w5c4Pv0nKKWswBbgNa31Vs/kkvZDGc/P9vsjFgHJnVZP8kzrQmv9ktY6Q2ud4XBEdJmXkmJi7twoCgur/VpMamtd1NZ2bHGzGYKDweFQNDVpqqs1NTWaurqhV4CDB90jaletipCzPwFo+nQzdrti40YLv/xlOL/61egpJgD79oHd7v53f/55OytXzhqW/cyXszwK+COQr7V+ttOst4H7Pc/vB97qNP0+z9meRUB1p0Ojfk2cqJg7N5qiojpqavzb/s/JMXHqlBmTCdra4Px5TVCQorhY43S6v32wsNDMV18Z04Wem1uJyaS4447eb44t/OPECSebN9spK3P4O5VBOXgwhnfeaeP11x3U1NgB9wfk7bf3PX5qoHz5T7gWuBe4XimV7XncDPwaWK6UOg7c6Pkd4H2gADgBbAS+52sy48fD0qXjOHOmlupq/3cmVFRYuXjRRmGhmdBQRXS0e3p0NISEKAoKzJSV2aioMK5HtaCglsrKJr797XGGvaYYvMmTFRs2pBAUBCUlIf5OZ0i++iqaigr3iYXHHjvIAw9M5I03Krjzzvh+1vRdv52ynr6Q3hpHN/SwvAY2DDSRiAi47bYp7N17NqAu9LNYNNOnu7BYwGJxbwaHw/1z+nQnn3+uDW36to+odTo1//APCfzlLyXGvbgYkIQEmD49nCeeKKa6OqL/FUaRr76K4X//71JaWkJITIymo8diaAJiBIRSsGHDVbz7bm5A3YJg5Ur3xVntZ17MZoXVqmht1Tid7sOfFSvaL+Ay7oBUaygpacJqNXH77TFs3Vo+qo7XxwqLRWG1migqChtz29/9wRVGbGyDoa8bEOM0x48PYcuWHJqaXDidutvDbHb/s3ae1n4mxOWix3WcTnfLwWTqvky73tZrj2k2K8rKXFRVaerrO/Iwm91ne6qqNGVlLsxmZVjM9mXa2jSnTtXT3Ozk+utD0FrhcvX8cOdEt2XaR1X2tp7LpbBYui+jtfKcybi8Y547B8eP1/DDH1Z368A0m13ewWS9sdmc3ZZxj3J19dkhajJprFbnsMe0Wp288soknnnmqOf1e962AxEQLZTz5+t58cXeOyI//ng8zz2XzXvvdVzenZJSRXp6M3v3OigqCutxvaVLS7nzzhj+7d/qKCzsaLLefXcJZWWwbVtCj+u1x/ztb7O9o1iLihRZWRZvzClTGomNdReK4mInb72VYEjM3t7n8eN9v8877ug95o4dvR8jd8TsWKZj2wZf9jFdrlLuvDOMCRNqusS8886yfv+e776bPKj9dsmSi559aHhjNjVZWLXqIhDf57YdiIAoKNXVVjZs6D1xu30i7747jrVrL3inpac7KCxUxMU1s3Bhz822K6+0c/JkNUFBcNttHa//6KPXsHBhIXfc0fvJJ7t9Im+/3REzLk6zfLnZG7O9mIC7RdL++kON6Y/3KTElZm8xH3vsWv7lX3oN101AHPIIIcaGUVVQ0tMHNwYgObmVqKjBdZpKTIkpMX0XEIc8vkhPL2PVqkXExOQD7o7LwsLGfteLiwti6VIbKSmxlJfXAbB7dw7Q/5gCiSkxJWZOv+t1NmoKSnm5jSef/Mz7+5VXKsLCNNXdL8jsoqmpja1bW4mJOeOddt99vg0ak5gS83KPef/9A7tRwKg55DlzJsJzYyP3IzzcQmxs/02z2to2qqutXdadNm2SxJSYEtPAmO1GTQtFKd3lzEpYmIWysr5v4NsuJKSty7q+3rJRYkpMiTmw/pSAaaH0lnd/76e3e8b6sh0kpsSUmEO75/KlAqKgTJtm4+GHZ2K10u0b9h56aCarVh1nzZoL3db7p3+6luefX8DEiVas1q4bJiHBTFxcEFu2mJk2rWt1VkqxZ88EiSkxJWY/MQcqIApKfn4r//iPp3nwwVksXx5PWJjyPmpq6rFaex5u/MILn7Fo0WmuuMLBgw/OIjra5F3PZlPU1bVisXS/CENrzYIFRRJTYkrMfmIOVED0oSilmTevjttuKyYjo5LvfjcJgAkTxnHPPTlcc01jr3ftnj+/lH//dzsVFcX87ndxBAfbsFjMOJ0uHn20kqVLex4ZaLE4JabElJg+xByIgCgo4L4Z9KpVFVy8qHjssSoAfvnLnu8F63AoEhJCvefW3cOJG/jJT0Jpa2sgOrqZn/2s51NsU6ZYvR1NElNiSsy+Y5oG+P0bAVFQgoKcLFzYcdHSN77h/tnS4qShwUJ6ehBhYR03MYqODmbSpAR27SolPd1FWpp73YUL3fOVspObW0pkpO7yugBf//osDh8+QVpalcSUmBKzn5iHDh1jIHy+SfVwSkxM048//odu0/PzzRw8GMfHHyeQnX2KL7/sGJnjdEJrKz12TrW0wOefhzBxYiNPP53Kjh0nKS3tuANcs6eY2+3dc5GYElNido35k5/4fpPqgGih1NWZOX68e9PKYtEsWFCK1ZrIc8+1csUVHcvMnOm++/yXX1oICel+I+vExEZmzNB8+eUZPvjARHh4x7obNozjqadqSE7ufswoMSWmxOxY9/vfH8dPftJtlV4FREFpbTWRnNz7jWPMZjNFReFcfXXHhpwyxUFhYSN2u6vXdePi7NTWtmE202WZadMmUVxcyDXX1ElMiSkx+4w5uddYPQmI08ZCiLFh1BQUk0nz6KPzeh3t15frr3eRlmb3rutrv5HElJiXe8yBCohDHl+sXVuCzTaZJ564GoD8/FO89lobDkffXwSWmhpJU1MbCxZc6Z32H/+xF637v4pSYkrMyz3m889/3m+8zkZNQdm8eTxbtxZ6f//mN0u45hpFdnbfjazjx6v4zW9isVhOeaft2rWAV1892/tKElNiSkwAMjOv5okn+g3pNWoKismkWbOm416X7vtk9n/TGIBZs8q6XKNgsaRITIkpMX2IaTZP9Wk9b+wBLS2EEH0IiIISHd3a6z0wZ88O5m9/O0hKSmW3eenpkSxfbiY8vHvvUUiIwuEwc/x4K9HR3b/W9NvfPi8xJabE9CHmQAREQQE4ebKRFSviuOqqrhtr8eIpvPhiGLNn93ytwqlTLUybFsqKFXFYO33FcFiYidBQG4cOBRMf37133OWSmBJTYvoScyACog+losLGkSOKkyfLmDoV1q2b4J33wgu5zJpl6vEKyuzsKvbtC+bcuXpMpjoefvgKbDb3Wyorq+Ovf60iJaXngTyvvZbItdeel5gSU2L2E3MgAqKggGb8eBdVVYr8fEVmprtD6Uc/iiY7O5hZs3rvUIqObiEkxEVrq+IXvyjD5VJERbXy+ONJHDvWytKltT2uZzK5JKbElJg+xByIACko7m/fi452f8dvVJS7yeZw2HpcdsIECzfeOIeNG/cBEBYGoAkObkFrCA/vPc6DD07D6mnvSUyJKTF9i+mrgCgo0dGtPPnktd2m/+1vWVy8GMI///MUoqIivdNNJhN5eSepqdFs2BDL7NldT23V1zfw618fZOpUU7fXtVqtPPfcp9x5p+aHP5SYElNi9hdzIALi9gVKqYtAPVDm71wGKBbJeaSMxrzHSs4TtdZxvqwcEAUFQCmV5es9FwKF5DxyRmPel2POAXPaWAgx+klBEUIYJpAKykv+TmAQJOeRMxrzvuxyDpg+FCHE6BdILRQhxCjn94KilFqllDqqlDqhlHrK3/n0Ril1Sin1lVIqWymV5ZkWrZTappQ67vkZFQB5vqyUKlVK5XSa1mOeyu13nm1/WCk1L4By/plSqsizvbOVUjd3mve0J+ejSqmVfso5WSn1iVIqTymVq5R6zDM9YLd1Hzkbt6211n57AGbgJDAFsAGHgBn+zKmPXE8BsZdM+7/AU57nTwH/JwDyXArMA3L6yxO4GfgAUMAiYF8A5fwz4Ic9LDvDs5/Ygcme/cfsh5zHA/M8z8OAY57cAnZb95GzYdva3y2UhcAJrXWB1roFeB1Y7eecBmI18Irn+SvAGv+l4qa13gVUXDK5tzxXA69qt71ApFKq/3sMGqyXnHuzGnhda92stS4ETuDej0aU1vq81vpLz/NaIB9IJIC3dR8592bA29rfBSUR6HxPu3P0/Qb9SQMfKaUOKKXWe6YlaK3Pe55fABL8k1q/essz0Lf/9z2HBy93OpwMuJyVUpOAucA+Rsm2viRnMGhb+7ugjCZLtNbzgJuADUqppZ1nancbMeBPmY2WPIEXgBQgHTgPPOPXbHqhlAoFtgA/0FrXdJ4XqNu6h5wN29b+LihFQHKn35M80wKO1rrI87MU+Bvupl9Je7PV87PUfxn2qbc8A3b7a61LtNZOrbUL2EhHUztgclZKWXH/Y76mtd7qmRzQ27qnnI3c1v4uKF8AqUqpyUopG3AX8Lafc+pGKRWilAprfw6sAHJw53q/Z7H7gbf8k2G/esvzbeA+zxmIRUB1p+a6X13Sv3Ab7u0N7pzvUkrZlVKTgVRgvx/yU8AfgXyt9bOdZgXstu4tZ0O39Uj3NPfQk3wz7t7mk8CP/Z1PLzlOwd3bfQjIbc8TiAG2A8eBj4HoAMj1r7ibra24j3m/01ueuM84/Idn238FZARQzn/25HTYs2OP77T8jz05HwVu8lPOS3AfzhwGsj2PmwN5W/eRs2HbWkbKCiEM4+9DHiHEGCIFRQhhGCkoQgjDSEERQhhGCooQwjBSUIQQhpGCIoQwjBQUIYRh/j9TYBpaANngzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(state[0])#show the frame in colored form before processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1ec59f9-dcf0-453f-9fcf-0bd09fac6f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1152 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,16))\n",
    "for idx in range(state.shape[3]):\n",
    "    plt.subplot(1,4,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8413356f-3f0b-4f3e-9938-418fee64a257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the RL Model\n",
    "#Import os for file path management\n",
    "import os\n",
    "#import PPO for algos\n",
    "from stable_baselines3 import PPO\n",
    "#import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e30ed30f-9037-4112-9170-de7fbe8735e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to save models after x amount of steps\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):#check frequency, how often to save the model, save_path, where to save the model\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "624f84db-20e0-4e37-857a-5b51327ce591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computing\\Desktop\\MSc-Robotics-and-Autonomous-Systems\\Advanced Machine Learning\\Assignment Task 2\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_DIR = '../../../train/'#CREATE THESE ON THE DESKTOP IF THE GIT REPO IS CLONES ON THE DESKTOP\n",
    "LOG_DIR = '../../..//logs/'\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f692b553-accb-4712-9793-4329b9557acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup callback Saves the model every 10,thousand steps at the desired location\n",
    "callback = TrainAndLoggingCallback(check_freq=1000,save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24bc5dcb-748d-47ce-9751-c1de15fceebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "#CREATING AN AI MODEL\n",
    "#Setup the MODEL: Machine learning/Deep Learning/ Reinforcement Learning, Ai model\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001,n_steps=512)#using the CNN cLassifier, tensorboard allows us to see how the training is performing, learning rate determines how fast the ai is learning\n",
    "#n_steps is how many frames to wait per game before updating the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92c4423f-f85f-4011-867b-885b15831508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ../../..//logs/PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 78  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 6   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 78            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 13            |\n",
      "|    total_timesteps      | 1024          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.4973796e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.000133      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 183           |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -4.16e-05     |\n",
      "|    value_loss           | 441           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 84            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 18            |\n",
      "|    total_timesteps      | 1536          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6935595e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.00858       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.684         |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000517     |\n",
      "|    value_loss           | 2.61          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 84            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 24            |\n",
      "|    total_timesteps      | 2048          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.0324015e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.000121      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.387         |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000106     |\n",
      "|    value_loss           | 0.821         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 86            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 29            |\n",
      "|    total_timesteps      | 2560          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6038615e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.0152       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0904        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -4.44e-05     |\n",
      "|    value_loss           | 0.476         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 86            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 35            |\n",
      "|    total_timesteps      | 3072          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.9161255e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.00489      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.102         |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.000185     |\n",
      "|    value_loss           | 0.321         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 3584         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.246846e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | -0.00467     |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.000158    |\n",
      "|    value_loss           | 0.661        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 87            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 46            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5591732e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.00498      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0976        |\n",
      "|    n_updates            | 70            |\n",
      "|    policy_gradient_loss | -8.07e-05     |\n",
      "|    value_loss           | 0.324         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 4608         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.181894e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.00453      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000191    |\n",
      "|    value_loss           | 0.258        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 88            |\n",
      "|    iterations           | 10            |\n",
      "|    time_elapsed         | 57            |\n",
      "|    total_timesteps      | 5120          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.3753763e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.0046        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0847        |\n",
      "|    n_updates            | 90            |\n",
      "|    policy_gradient_loss | -0.000158     |\n",
      "|    value_loss           | 0.224         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 89            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 62            |\n",
      "|    total_timesteps      | 5632          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1973665e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.00189      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0539        |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000278     |\n",
      "|    value_loss           | 0.192         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.404027e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.00413      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0939       |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.000322    |\n",
      "|    value_loss           | 0.192        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 6656         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.082134e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | -0.00322     |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.163        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.000198    |\n",
      "|    value_loss           | 0.403        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 89            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 80            |\n",
      "|    total_timesteps      | 7168          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.6064607e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.00573       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.162         |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.000166     |\n",
      "|    value_loss           | 0.291         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 15            |\n",
      "|    time_elapsed         | 85            |\n",
      "|    total_timesteps      | 7680          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3102079e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.00469      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.07          |\n",
      "|    n_updates            | 140           |\n",
      "|    policy_gradient_loss | -0.000279     |\n",
      "|    value_loss           | 0.159         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 89            |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 91            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2085303e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.000331     |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0773        |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -6.24e-05     |\n",
      "|    value_loss           | 0.112         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 17            |\n",
      "|    time_elapsed         | 96            |\n",
      "|    total_timesteps      | 8704          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9223196e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.0268        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 118           |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | 0.000207      |\n",
      "|    value_loss           | 386           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 102          |\n",
      "|    total_timesteps      | 9216         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.737405e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.0172       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 38.6         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 8.68e-05     |\n",
      "|    value_loss           | 93.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 9728         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.128301e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.0377       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.000292    |\n",
      "|    value_loss           | 2.32         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 113           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.9054121e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.151         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.224         |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000368     |\n",
      "|    value_loss           | 0.979         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 118           |\n",
      "|    total_timesteps      | 10752         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3187178e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.0962       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.188         |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.000161     |\n",
      "|    value_loss           | 0.902         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 11264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.425622e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.0619       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.187        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000242    |\n",
      "|    value_loss           | 0.532        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 11776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.580361e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.00154      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.117        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -9.02e-05    |\n",
      "|    value_loss           | 0.316        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.864174e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.000983    |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.176        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -3.5e-05     |\n",
      "|    value_loss           | 0.424        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 141           |\n",
      "|    total_timesteps      | 12800         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1027907e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.00225       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.109         |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.000254     |\n",
      "|    value_loss           | 0.395         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 13312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.572002e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.00653     |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.284        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.000144    |\n",
      "|    value_loss           | 0.656        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 2.34748e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.00468     |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.000443   |\n",
      "|    value_loss           | 0.296       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.11787e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.00461    |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.346       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.000586   |\n",
      "|    value_loss           | 0.624       |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 29            |\n",
      "|    time_elapsed         | 163           |\n",
      "|    total_timesteps      | 14848         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8456637e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.00136       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.102         |\n",
      "|    n_updates            | 280           |\n",
      "|    policy_gradient_loss | -0.000562     |\n",
      "|    value_loss           | 0.216         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 30            |\n",
      "|    time_elapsed         | 169           |\n",
      "|    total_timesteps      | 15360         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2495515e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | -0.000809     |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0562        |\n",
      "|    n_updates            | 290           |\n",
      "|    policy_gradient_loss | -0.000309     |\n",
      "|    value_loss           | 0.147         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 174           |\n",
      "|    total_timesteps      | 15872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6945065e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.00729       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.125         |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.000273     |\n",
      "|    value_loss           | 0.217         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 32            |\n",
      "|    time_elapsed         | 180           |\n",
      "|    total_timesteps      | 16384         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7349841e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | -0.0113       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0518        |\n",
      "|    n_updates            | 310           |\n",
      "|    policy_gradient_loss | -0.00024      |\n",
      "|    value_loss           | 0.115         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 16896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.040578e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0877       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 212          |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -2.5e-05     |\n",
      "|    value_loss           | 488          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.976327e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.154        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0884       |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -9.81e-05    |\n",
      "|    value_loss           | 0.762        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 17920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.922793e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0262       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0593       |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000496    |\n",
      "|    value_loss           | 0.342        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 202           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9088737e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | -0.0317       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0757        |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.000161     |\n",
      "|    value_loss           | 0.266         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 37            |\n",
      "|    time_elapsed         | 208           |\n",
      "|    total_timesteps      | 18944         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3480545e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.11          |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0841        |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.000243     |\n",
      "|    value_loss           | 0.367         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 214           |\n",
      "|    total_timesteps      | 19456         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3341312e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | -0.0222       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0882        |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.000177     |\n",
      "|    value_loss           | 0.216         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 219           |\n",
      "|    total_timesteps      | 19968         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.0487427e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.291         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0925        |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.000329     |\n",
      "|    value_loss           | 0.202         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 40            |\n",
      "|    time_elapsed         | 225           |\n",
      "|    total_timesteps      | 20480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.2979914e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.00894       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0713        |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.000665     |\n",
      "|    value_loss           | 0.171         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 230           |\n",
      "|    total_timesteps      | 20992         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2728113e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.0128        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0657        |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -0.000285     |\n",
      "|    value_loss           | 0.192         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 236           |\n",
      "|    total_timesteps      | 21504         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5231391e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | -0.0075       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0888        |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.000285     |\n",
      "|    value_loss           | 0.258         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 22016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.842804e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.00486      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0895       |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.000253    |\n",
      "|    value_loss           | 0.153        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 44            |\n",
      "|    time_elapsed         | 247           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8735376e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | -0.000239     |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0716        |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -0.000415     |\n",
      "|    value_loss           | 0.169         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 253         |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 9.37318e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.00193     |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0407      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.000112   |\n",
      "|    value_loss           | 0.0993      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.645608e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.0284      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0489       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.000329    |\n",
      "|    value_loss           | 0.141        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 24064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.227801e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0071       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0464       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000364    |\n",
      "|    value_loss           | 0.109        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 269           |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4684821e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.00439       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 8.48          |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000498     |\n",
      "|    value_loss           | 9.71          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 90            |\n",
      "|    iterations           | 49            |\n",
      "|    time_elapsed         | 275           |\n",
      "|    total_timesteps      | 25088         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5636552e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.0386        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 189           |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | 9.64e-05      |\n",
      "|    value_loss           | 408           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 280          |\n",
      "|    total_timesteps      | 25600        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.931834e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.00608      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.136        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -1.43e-05    |\n",
      "|    value_loss           | 0.668        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 90           |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 287          |\n",
      "|    total_timesteps      | 26112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.510446e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0789       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0721       |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.000474    |\n",
      "|    value_loss           | 0.324        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 52            |\n",
      "|    time_elapsed         | 292           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3475302e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.00539       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0618        |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.000489     |\n",
      "|    value_loss           | 0.199         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 298           |\n",
      "|    total_timesteps      | 27136         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.5529294e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | -0.02         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0593        |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | -0.000491     |\n",
      "|    value_loss           | 0.195         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 303          |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.295066e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.00608     |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0525       |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.000467    |\n",
      "|    value_loss           | 0.174        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 309          |\n",
      "|    total_timesteps      | 28160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.574505e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.0333       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0845       |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.000482    |\n",
      "|    value_loss           | 0.171        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 56            |\n",
      "|    time_elapsed         | 314           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5509624e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | 0.0485        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0658        |\n",
      "|    n_updates            | 550           |\n",
      "|    policy_gradient_loss | -0.000292     |\n",
      "|    value_loss           | 0.222         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 57            |\n",
      "|    time_elapsed         | 320           |\n",
      "|    total_timesteps      | 29184         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9428087e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | 0.581         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0753        |\n",
      "|    n_updates            | 560           |\n",
      "|    policy_gradient_loss | -0.000175     |\n",
      "|    value_loss           | 0.14          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 325          |\n",
      "|    total_timesteps      | 29696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.830142e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.00578     |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0675       |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.000173    |\n",
      "|    value_loss           | 0.128        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 331          |\n",
      "|    total_timesteps      | 30208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.428058e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.01         |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0698       |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.000713    |\n",
      "|    value_loss           | 0.137        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 60            |\n",
      "|    time_elapsed         | 336           |\n",
      "|    total_timesteps      | 30720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5698642e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | 0.0098        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0475        |\n",
      "|    n_updates            | 590           |\n",
      "|    policy_gradient_loss | -0.000312     |\n",
      "|    value_loss           | 0.114         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 61            |\n",
      "|    time_elapsed         | 342           |\n",
      "|    total_timesteps      | 31232         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2859895e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | -0.00437      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0504        |\n",
      "|    n_updates            | 600           |\n",
      "|    policy_gradient_loss | -0.000281     |\n",
      "|    value_loss           | 0.162         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 62            |\n",
      "|    time_elapsed         | 347           |\n",
      "|    total_timesteps      | 31744         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.3965993e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | -0.0321       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.049         |\n",
      "|    n_updates            | 610           |\n",
      "|    policy_gradient_loss | -0.000494     |\n",
      "|    value_loss           | 0.133         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 63            |\n",
      "|    time_elapsed         | 353           |\n",
      "|    total_timesteps      | 32256         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5116722e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | -0.0108       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0509        |\n",
      "|    n_updates            | 620           |\n",
      "|    policy_gradient_loss | -0.000307     |\n",
      "|    value_loss           | 0.143         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 64            |\n",
      "|    time_elapsed         | 359           |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.8749534e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | 0.0972        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 200           |\n",
      "|    n_updates            | 630           |\n",
      "|    policy_gradient_loss | 0.000233      |\n",
      "|    value_loss           | 449           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 65            |\n",
      "|    time_elapsed         | 365           |\n",
      "|    total_timesteps      | 33280         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015228696 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.0721        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 37.4          |\n",
      "|    n_updates            | 640           |\n",
      "|    policy_gradient_loss | -4.62e-05     |\n",
      "|    value_loss           | 130           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 66            |\n",
      "|    time_elapsed         | 370           |\n",
      "|    total_timesteps      | 33792         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5776833e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.00512       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.187         |\n",
      "|    n_updates            | 650           |\n",
      "|    policy_gradient_loss | -0.000226     |\n",
      "|    value_loss           | 0.852         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 67            |\n",
      "|    time_elapsed         | 376           |\n",
      "|    total_timesteps      | 34304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6942271e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | -0.0253       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.136         |\n",
      "|    n_updates            | 660           |\n",
      "|    policy_gradient_loss | 3.96e-05      |\n",
      "|    value_loss           | 0.749         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 68            |\n",
      "|    time_elapsed         | 381           |\n",
      "|    total_timesteps      | 34816         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0255841e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.93         |\n",
      "|    explained_variance   | -0.0514       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.154         |\n",
      "|    n_updates            | 670           |\n",
      "|    policy_gradient_loss | 4.92e-05      |\n",
      "|    value_loss           | 0.65          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 69            |\n",
      "|    time_elapsed         | 387           |\n",
      "|    total_timesteps      | 35328         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2480497e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.0129        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.206         |\n",
      "|    n_updates            | 680           |\n",
      "|    policy_gradient_loss | -0.000168     |\n",
      "|    value_loss           | 0.526         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 392          |\n",
      "|    total_timesteps      | 35840        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.482533e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.105        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.127        |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.00054     |\n",
      "|    value_loss           | 0.489        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 71            |\n",
      "|    time_elapsed         | 398           |\n",
      "|    total_timesteps      | 36352         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9522384e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.00451       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.088         |\n",
      "|    n_updates            | 700           |\n",
      "|    policy_gradient_loss | -0.000155     |\n",
      "|    value_loss           | 0.285         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 72            |\n",
      "|    time_elapsed         | 403           |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.9588893e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.00353       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.128         |\n",
      "|    n_updates            | 710           |\n",
      "|    policy_gradient_loss | -0.000337     |\n",
      "|    value_loss           | 0.274         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 73            |\n",
      "|    time_elapsed         | 409           |\n",
      "|    total_timesteps      | 37376         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1686348e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.0148        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.102         |\n",
      "|    n_updates            | 720           |\n",
      "|    policy_gradient_loss | -0.000434     |\n",
      "|    value_loss           | 0.282         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 74            |\n",
      "|    time_elapsed         | 415           |\n",
      "|    total_timesteps      | 37888         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4570927e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.0865        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.227         |\n",
      "|    n_updates            | 730           |\n",
      "|    policy_gradient_loss | -0.000257     |\n",
      "|    value_loss           | 0.349         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 421          |\n",
      "|    total_timesteps      | 38400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.248162e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.00588      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0717       |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.000309    |\n",
      "|    value_loss           | 0.153        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 426          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.739422e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.00347      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0497       |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -8.78e-05    |\n",
      "|    value_loss           | 0.138        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 77            |\n",
      "|    time_elapsed         | 432           |\n",
      "|    total_timesteps      | 39424         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1541299e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.0503        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 19.2          |\n",
      "|    n_updates            | 760           |\n",
      "|    policy_gradient_loss | -9.25e-06     |\n",
      "|    value_loss           | 41.5          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 78            |\n",
      "|    time_elapsed         | 437           |\n",
      "|    total_timesteps      | 39936         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028152077 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.142         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 142           |\n",
      "|    n_updates            | 770           |\n",
      "|    policy_gradient_loss | -0.000844     |\n",
      "|    value_loss           | 434           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 443          |\n",
      "|    total_timesteps      | 40448        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.207727e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0791       |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -3.8e-05     |\n",
      "|    value_loss           | 1.22         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 80            |\n",
      "|    time_elapsed         | 448           |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.5989797e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.0812        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0913        |\n",
      "|    n_updates            | 790           |\n",
      "|    policy_gradient_loss | -3.76e-05     |\n",
      "|    value_loss           | 0.594         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 81            |\n",
      "|    time_elapsed         | 454           |\n",
      "|    total_timesteps      | 41472         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4887576e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | -0.0809       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0691        |\n",
      "|    n_updates            | 800           |\n",
      "|    policy_gradient_loss | -0.00026      |\n",
      "|    value_loss           | 0.362         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 82            |\n",
      "|    time_elapsed         | 459           |\n",
      "|    total_timesteps      | 41984         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8539449e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.00843       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0584        |\n",
      "|    n_updates            | 810           |\n",
      "|    policy_gradient_loss | -0.000244     |\n",
      "|    value_loss           | 0.335         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 83            |\n",
      "|    time_elapsed         | 465           |\n",
      "|    total_timesteps      | 42496         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5339232e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.274         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0697        |\n",
      "|    n_updates            | 820           |\n",
      "|    policy_gradient_loss | -5.74e-05     |\n",
      "|    value_loss           | 0.227         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 84            |\n",
      "|    time_elapsed         | 471           |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013719278 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | -0.0273       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0686        |\n",
      "|    n_updates            | 830           |\n",
      "|    policy_gradient_loss | -0.00101      |\n",
      "|    value_loss           | 0.198         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 85            |\n",
      "|    time_elapsed         | 477           |\n",
      "|    total_timesteps      | 43520         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.3243864e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.0774        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.185         |\n",
      "|    n_updates            | 840           |\n",
      "|    policy_gradient_loss | -0.000815     |\n",
      "|    value_loss           | 0.28          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 86            |\n",
      "|    time_elapsed         | 483           |\n",
      "|    total_timesteps      | 44032         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2064115e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.267         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0669        |\n",
      "|    n_updates            | 850           |\n",
      "|    policy_gradient_loss | -0.000383     |\n",
      "|    value_loss           | 0.186         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 87            |\n",
      "|    time_elapsed         | 488           |\n",
      "|    total_timesteps      | 44544         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5550136e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | -0.00917      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0444        |\n",
      "|    n_updates            | 860           |\n",
      "|    policy_gradient_loss | -0.000209     |\n",
      "|    value_loss           | 0.132         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 88            |\n",
      "|    time_elapsed         | 494           |\n",
      "|    total_timesteps      | 45056         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6794804e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.00281       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0783        |\n",
      "|    n_updates            | 870           |\n",
      "|    policy_gradient_loss | -0.000746     |\n",
      "|    value_loss           | 0.151         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 499          |\n",
      "|    total_timesteps      | 45568        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.572661e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0644       |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.000751    |\n",
      "|    value_loss           | 0.138        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 46080        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.885679e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | -0.00829     |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0548       |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.000679    |\n",
      "|    value_loss           | 0.15         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 510          |\n",
      "|    total_timesteps      | 46592        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.846474e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.108        |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00056     |\n",
      "|    value_loss           | 0.153        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 92            |\n",
      "|    time_elapsed         | 516           |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6576024e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.218         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0817        |\n",
      "|    n_updates            | 910           |\n",
      "|    policy_gradient_loss | -0.000422     |\n",
      "|    value_loss           | 0.167         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 93            |\n",
      "|    time_elapsed         | 521           |\n",
      "|    total_timesteps      | 47616         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013162545 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.92         |\n",
      "|    explained_variance   | 0.0745        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 113           |\n",
      "|    n_updates            | 920           |\n",
      "|    policy_gradient_loss | 0.000316      |\n",
      "|    value_loss           | 313           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 94            |\n",
      "|    time_elapsed         | 527           |\n",
      "|    total_timesteps      | 48128         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00039371825 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.91         |\n",
      "|    explained_variance   | 0.239         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 41.3          |\n",
      "|    n_updates            | 930           |\n",
      "|    policy_gradient_loss | 0.000529      |\n",
      "|    value_loss           | 129           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 95            |\n",
      "|    time_elapsed         | 532           |\n",
      "|    total_timesteps      | 48640         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3747208e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.91         |\n",
      "|    explained_variance   | 0.025         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0824        |\n",
      "|    n_updates            | 940           |\n",
      "|    policy_gradient_loss | -0.000205     |\n",
      "|    value_loss           | 0.75          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 539          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.862544e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0862       |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | 5.2e-05      |\n",
      "|    value_loss           | 0.614        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 97            |\n",
      "|    time_elapsed         | 544           |\n",
      "|    total_timesteps      | 49664         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6794303e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.91         |\n",
      "|    explained_variance   | 0.0498        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0651        |\n",
      "|    n_updates            | 960           |\n",
      "|    policy_gradient_loss | 0.000135      |\n",
      "|    value_loss           | 0.561         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 98            |\n",
      "|    time_elapsed         | 550           |\n",
      "|    total_timesteps      | 50176         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0135776e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.91         |\n",
      "|    explained_variance   | 0.00209       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0584        |\n",
      "|    n_updates            | 970           |\n",
      "|    policy_gradient_loss | -0.000106     |\n",
      "|    value_loss           | 0.427         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 91            |\n",
      "|    iterations           | 99            |\n",
      "|    time_elapsed         | 555           |\n",
      "|    total_timesteps      | 50688         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.6220845e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.91         |\n",
      "|    explained_variance   | 0.017         |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0666        |\n",
      "|    n_updates            | 980           |\n",
      "|    policy_gradient_loss | -2.53e-05     |\n",
      "|    value_loss           | 0.292         |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Train the AI model, this is where it starts to learn ,  how many frames the AI sees for every single game\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:304\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    293\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    301\u001b[0m     reset_num_timesteps: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    302\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPPO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPPO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:250\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    246\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 250\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:207\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    204\u001b[0m             terminal_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mpredict_values(terminal_obs)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    205\u001b[0m         rewards[idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m terminal_value\n\u001b[1;32m--> 207\u001b[0m \u001b[43mrollout_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_episode_starts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs \u001b[38;5;241m=\u001b[39m new_obs\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_episode_starts \u001b[38;5;241m=\u001b[39m dones\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:432\u001b[0m, in \u001b[0;36mRolloutBuffer.add\u001b[1;34m(self, obs, action, reward, episode_start, value, log_prob)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(reward)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_starts[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(episode_start)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos] \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_probs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos] \u001b[38;5;241m=\u001b[39m log_prob\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train the AI model, this is where it starts to learn ,  how many frames the AI sees for every single game\n",
    "model.learn(total_timesteps=1000000,callback=callback) # can remove callback to prevent saving the data\n",
    "\n",
    "#LOSS should be going down and explained_variance should be going up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1473d163-4b1e-464d-a2ea-e12a712469a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../../../mario_testmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef5ccb56-796d-4a26-b0fb-18f3de68ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test out the model\n",
    "\n",
    "\n",
    "# Load model\n",
    "model = PPO.load('../../../train/best_model_51000')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e81480bb-9f97-4deb-9272-6d15f468df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a77c1ce-251a-499d-b93a-40f2d814a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \n\u001b[0;32m      6\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(state)\n\u001b[1;32m----> 7\u001b[0m     state, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_frame_stack.py:48\u001b[0m, in \u001b[0;36mVecFrameStack.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     46\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]], np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mndarray, List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]],]:\n\u001b[1;32m---> 48\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     observations, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstackedobs\u001b[38;5;241m.\u001b[39mupdate(observations, dones, infos)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m observations, rewards, dones, infos\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 43\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     47\u001b[0m             \u001b[38;5;66;03m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     48\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\core.py:323\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m--> 323\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, done, info\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nes_py\\wrappers\\joypad_space.py:74\u001b[0m, in \u001b[0;36mJoypadSpace.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mTake a step using the given action.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# take the step and record the output\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\time_limit.py:18\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m     observation, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nes_py\\nes_env.py:293\u001b[0m, in \u001b[0;36mNESEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrollers[\u001b[38;5;241m0\u001b[39m][:] \u001b[38;5;241m=\u001b[39m action\n\u001b[0;32m    292\u001b[0m \u001b[38;5;66;03m# pass the action to the emulator as an unsigned byte\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;66;03m# get the reward for this step\u001b[39;00m\n\u001b[0;32m    295\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_reward()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the game \n",
    "state = env.reset()\n",
    "# Loop through the game\n",
    "while True: \n",
    "    \n",
    "    action, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229d847-6a91-4f31-bbaa-85d8d27a1d81",
   "metadata": {},
   "source": [
    "#Run this code in the logs/PPO_1 To see performance metrics via tensorboard if it is installed\n",
    "\n",
    "tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4a5465-667f-4c54-b07d-39ccd9d6033f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Close the program if it still persits\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "#Close the program if it still persits\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b3fae1-588b-4a96-ac19-f81bb2b9fa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
